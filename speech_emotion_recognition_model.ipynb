{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd1zknE2IRew"
   },
   "source": [
    "\n",
    "[Dataset](https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "4CKPHhxqoeid",
    "outputId": "e8e2a39c-0acc-40ba-d7e0-45c26d611c2b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "Root = \"C:\\\\Users\\\\Yogita\\\\Downloads\\\\speech-emotion-recognition-ravdess-data\"\n",
    "os.chdir(Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHlkrPZPpXlI",
    "outputId": "923ccdce-3e57-4b3b-e138-a1651d77118a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is CCC9-3214\n",
      "\n",
      " Directory of C:\\Users\\Yogita\\Downloads\\speech-emotion-recognition-ravdess-data\n",
      "\n",
      "29-04-2023  16:12    <DIR>          .\n",
      "16-06-2023  11:33    <DIR>          ..\n",
      "25-04-2023  21:34    <DIR>          Actor_01\n",
      "25-04-2023  21:35    <DIR>          Actor_02\n",
      "25-04-2023  21:35    <DIR>          Actor_03\n",
      "25-04-2023  21:35    <DIR>          Actor_04\n",
      "25-04-2023  21:35    <DIR>          Actor_05\n",
      "25-04-2023  21:35    <DIR>          Actor_06\n",
      "25-04-2023  21:35    <DIR>          Actor_07\n",
      "25-04-2023  21:35    <DIR>          Actor_08\n",
      "25-04-2023  21:35    <DIR>          Actor_09\n",
      "25-04-2023  21:35    <DIR>          Actor_10\n",
      "25-04-2023  21:35    <DIR>          Actor_11\n",
      "25-04-2023  21:35    <DIR>          Actor_12\n",
      "25-04-2023  21:35    <DIR>          Actor_13\n",
      "25-04-2023  21:35    <DIR>          Actor_14\n",
      "25-04-2023  21:35    <DIR>          Actor_15\n",
      "25-04-2023  21:35    <DIR>          Actor_16\n",
      "25-04-2023  21:35    <DIR>          Actor_17\n",
      "25-04-2023  21:35    <DIR>          Actor_18\n",
      "25-04-2023  21:35    <DIR>          Actor_19\n",
      "25-04-2023  21:35    <DIR>          Actor_20\n",
      "25-04-2023  21:35    <DIR>          Actor_21\n",
      "25-04-2023  21:36    <DIR>          Actor_22\n",
      "25-04-2023  21:36    <DIR>          Actor_23\n",
      "25-04-2023  21:36    <DIR>          Actor_24\n",
      "02-05-2023  14:25         1,342,059 modelForPrediction1.sav\n",
      "               1 File(s)      1,342,059 bytes\n",
      "              26 Dir(s)  24,931,311,616 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_IehQoF0pZxl"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cOrKu9Cnphen"
   },
   "outputs": [],
   "source": [
    "#Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ljV0QLcXpmRP"
   },
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O46uIg3kpzrG"
   },
   "outputs": [],
   "source": [
    "#Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"C:\\\\Users\\\\Yogita\\\\Downloads\\\\speech-emotion-recognition-ravdess-data\\\\Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc=True, chroma=True, mel=True):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gE_MSQYDqPqg"
   },
   "outputs": [],
   "source": [
    "#Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fo872mW8urUM",
    "outputId": "38e80fb8-a449-4578-c140-bccbc724a593"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.10513763e+02,  4.24358864e+01, -9.45346069e+00, ...,\n",
       "         1.64437573e-04,  9.46390792e-05,  5.23333256e-05],\n",
       "       [-4.56259705e+02,  3.64639740e+01, -1.66679306e+01, ...,\n",
       "         9.26713750e-04,  4.61736636e-04,  3.27778573e-04],\n",
       "       [-5.60618164e+02,  5.78945961e+01, -8.87167645e+00, ...,\n",
       "         6.46989676e-04,  3.31015413e-04,  1.85833647e-04],\n",
       "       ...,\n",
       "       [-6.28208679e+02,  6.78257980e+01,  3.31187057e+00, ...,\n",
       "         1.69829382e-05,  2.15309719e-05,  8.10299025e-06],\n",
       "       [-6.99333679e+02,  5.65012970e+01, -4.47911210e-02, ...,\n",
       "         4.29499642e-06,  3.19059973e-06,  2.37793006e-06],\n",
       "       [-5.39937622e+02,  4.63176537e+01, -8.90276718e+00, ...,\n",
       "         1.99300077e-04,  1.41271099e-04,  9.42719635e-05]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNIOCRQ6qWOq",
    "outputId": "614efdc6-f7bb-445b-d90b-034cd79feaa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 39)\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqoLMHgsqcP8",
    "outputId": "33a54b84-018c-4078-8182-e8127fc645eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bQsjvZiwqcTN"
   },
   "outputs": [],
   "source": [
    "#Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmZiXDHPqcV5",
    "outputId": "b7d8eb01-729f-42bc-c9ca-ff87ce02540f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lumz8vRQqcYs"
   },
   "outputs": [],
   "source": [
    "#Predict for the test set\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m604kmiFtxLP",
    "outputId": "9d7e1922-1bec-4a52-d98f-2568fe627d21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['calm', 'happy', 'happy', 'happy', 'calm', 'calm', 'disgust',\n",
       "       'disgust', 'happy', 'happy', 'calm', 'fearful', 'fearful',\n",
       "       'fearful', 'disgust', 'fearful', 'fearful', 'calm', 'fearful',\n",
       "       'happy', 'calm', 'happy', 'disgust', 'happy', 'happy', 'disgust',\n",
       "       'disgust', 'disgust', 'happy', 'fearful', 'happy', 'happy',\n",
       "       'happy', 'calm', 'disgust', 'happy', 'calm', 'fearful', 'calm'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrCVcauwqkFs",
    "outputId": "89aad7da-00e2-45de-9fe5-15b5190063ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.92%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vJ8_B3O0qkJG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ry4if_sqkLr",
    "outputId": "20378ec2-e8f0-4bd0-bffe-1d28cd2f9e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.8       , 0.8       , 0.72727273])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "0Rt9YfZkCO5A",
    "outputId": "a0bff042-6fd2-466f-b043-5bb27cb96eda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disgust</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgust</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disgust</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fearful</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fearful</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fearful</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Predicted\n",
       "0      calm      calm\n",
       "1     happy     happy\n",
       "2     happy     happy\n",
       "3     happy     happy\n",
       "4      calm      calm\n",
       "5      calm      calm\n",
       "6   disgust   disgust\n",
       "7   disgust   disgust\n",
       "8     happy     happy\n",
       "9     happy     happy\n",
       "10     calm      calm\n",
       "11  fearful   fearful\n",
       "12  fearful   fearful\n",
       "13  fearful   fearful\n",
       "14  disgust   disgust\n",
       "15  fearful   fearful\n",
       "16  fearful   fearful\n",
       "17  fearful      calm\n",
       "18  fearful   fearful\n",
       "19  fearful     happy"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Actual': y_test, 'Predicted':y_pred})\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eYPWbWLBqkN7"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Writing different model files to file\n",
    "with open( 'modelForPrediction1.sav', 'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dw0IfunzvqtV",
    "outputId": "255e2b31-7f43-4d83-9fd3-97a4d5e7daf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['calm'], dtype='<U7')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'modelForPrediction1.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb')) # loading the model file from the storage\n",
    "\n",
    "feature=extract_feature(\"C:\\\\Users\\\\Yogita\\\\Downloads\\\\speech-emotion-recognition-ravdess-data\\\\Actor_01\\\\03-01-02-01-01-01-01.wav\", mfcc=True, chroma=True, mel=True)\n",
    "\n",
    "feature=feature.reshape(1,-1)\n",
    "\n",
    "prediction=loaded_model.predict(feature)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "grRD5MrTxOaL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.09056824e+02,  5.57343063e+01,  2.66831017e+00,\n",
       "         1.63625717e+01,  3.34478068e+00, -1.12484837e+00,\n",
       "        -5.81839275e+00, -8.99917793e+00, -9.00914574e+00,\n",
       "         1.83856320e+00, -4.59688282e+00,  8.66339445e-01,\n",
       "        -5.26519156e+00,  2.29214072e+00, -3.53222799e+00,\n",
       "        -4.00518894e+00, -9.01319921e-01, -2.07280874e+00,\n",
       "        -4.99126625e+00, -2.39771295e+00, -3.05734110e+00,\n",
       "        -5.33976030e+00, -4.98443782e-01, -4.57491541e+00,\n",
       "        -1.80997217e+00, -7.89660990e-01, -1.83776867e+00,\n",
       "        -4.33098048e-01, -2.91427803e+00, -1.27407944e+00,\n",
       "        -3.70224690e+00, -6.55556202e-01, -1.61118352e+00,\n",
       "        -1.53617072e+00, -3.60538459e+00, -3.62369895e+00,\n",
       "        -4.16981697e+00, -2.33298492e+00, -1.29951084e+00,\n",
       "        -1.49847436e+00,  6.03868425e-01,  6.26373410e-01,\n",
       "         6.96483552e-01,  6.88914716e-01,  6.79974377e-01,\n",
       "         6.92952931e-01,  6.99749649e-01,  7.20743597e-01,\n",
       "         7.34567702e-01,  7.47884452e-01,  7.74087787e-01,\n",
       "         7.32814670e-01,  1.30654439e-06,  2.63914480e-05,\n",
       "         2.27657729e-04,  6.17711479e-03,  1.89291555e-02,\n",
       "         2.76748072e-02,  1.53324651e-02,  2.02345708e-03,\n",
       "         1.00349896e-02,  1.98738556e-02,  1.32849514e-02,\n",
       "         1.32274227e-02,  2.33363565e-02,  6.68408209e-03,\n",
       "         3.58397420e-03,  2.88147596e-03,  8.23420472e-03,\n",
       "         1.18965944e-02,  1.92299075e-02,  2.14630943e-02,\n",
       "         3.76221887e-03,  1.63726660e-03,  1.64405454e-03,\n",
       "         6.48166612e-03,  1.30829457e-02,  1.67167047e-03,\n",
       "         5.25044976e-04,  3.40918981e-04,  2.62030936e-03,\n",
       "         5.72679425e-03,  2.37368001e-03,  5.23993745e-04,\n",
       "         2.01674862e-04,  2.57294218e-04,  3.72829643e-04,\n",
       "         1.20406898e-04,  1.00045363e-04,  5.00275310e-05,\n",
       "         1.71895867e-04,  1.99879214e-04,  1.48093590e-04,\n",
       "         4.62380820e-04,  1.97038622e-04,  7.88333491e-05,\n",
       "         1.83292213e-04,  1.88297767e-04,  4.42417746e-04,\n",
       "         1.80025538e-03,  9.21949046e-04,  1.97928195e-04,\n",
       "         1.02955797e-04,  2.47114047e-04,  9.97278490e-04,\n",
       "         1.99792121e-04,  6.20311912e-05,  3.40740429e-04,\n",
       "         4.34924383e-04,  7.76792731e-05,  1.56400769e-04,\n",
       "         1.13388489e-03,  4.71329433e-04,  1.28258427e-04,\n",
       "         1.87313330e-04,  2.43678354e-04,  2.24207062e-04,\n",
       "         1.66565369e-04,  2.50821904e-04,  1.02729804e-03,\n",
       "         2.76448234e-04,  6.23665037e-05,  9.62174745e-05,\n",
       "         4.97538058e-05,  6.41178558e-05,  6.08843729e-05,\n",
       "         1.04783961e-04,  9.13707845e-05,  1.30088287e-04,\n",
       "         1.46856575e-04,  1.36625313e-04,  3.91240028e-04,\n",
       "         2.21093811e-04,  1.40775664e-04,  1.41634693e-04,\n",
       "         4.33036839e-05,  5.00952410e-05,  2.01293587e-05,\n",
       "         1.44178111e-05,  1.13336873e-05,  1.36046547e-05,\n",
       "         1.70999920e-05,  2.82998226e-05,  3.14157187e-05,\n",
       "         4.98632944e-05,  5.88906441e-05,  8.37483385e-05,\n",
       "         7.61683768e-05,  5.97868093e-05,  2.75052207e-05,\n",
       "         6.99020802e-06,  6.03043372e-06,  6.54936366e-06,\n",
       "         1.37693669e-05,  1.33430722e-05,  2.47184507e-05,\n",
       "         1.97433092e-05,  1.77091551e-05,  4.75227826e-05,\n",
       "         3.01743712e-05,  3.37255078e-05,  2.09672780e-05,\n",
       "         2.94377533e-05,  2.72917132e-05,  4.82362339e-05,\n",
       "         4.88119695e-05,  5.22217015e-05,  3.92525071e-05,\n",
       "         3.65118540e-05,  3.38605678e-05,  1.48681975e-05,\n",
       "         6.66972210e-06,  6.87130114e-06,  5.16396221e-06,\n",
       "         5.77914034e-06,  4.89109061e-06,  4.70851273e-06,\n",
       "         2.82708083e-06,  2.46006584e-06,  1.46975708e-06]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b_mwxpsyugl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
